{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting monthly revenue on 2026 data w/ base price & dynamic price**"
      ],
      "metadata": {
        "id": "teXkwSQsWFgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a preface to this code and what it does:\n",
        "\n",
        "**All necessary files should be found in the folder called \"forPredictions/\"**\n",
        "\n",
        "This model will need **5** different csv files:\n",
        "- parkingdata_streamlined.csv\n",
        "- monthlyParkingRevenue.csv\n",
        "- basePrice.csv\n",
        "- 2026predictedparkingdata_streamlined.csv\n",
        "- dynamicModelSheet.csv\n",
        "\n",
        "---\n",
        "This model will first learn on the historic data (parkingdata_streamlined.csv ; monthlyParkingRevenue.csv). It will also learn using the price table set that can be set easily. In the learning phase, it will use the basePrice.csv to order to train and test.\n",
        "\n",
        "---\n",
        "In the next phase, it will use the trained and tested random forest model and have it predict on the 2026 data. It will output the predicted monthly revenue using the base prices.\n",
        "\n",
        "---\n",
        "In the last phase, it will use the model again on the 2026 data, but this time it will use the dynamic pricing table instead. It will output the predicted monthly revenue if we used the dynamic pricing model in 2026."
      ],
      "metadata": {
        "id": "E8XHQHwKgWJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There will be 3 different outputs that represent each phase:\n",
        "- predictedMonthlyRevenue_historical.csv\n",
        "- predictedMonthlyRevenue_2026standard.csv\n",
        "- predictedMonthlyRevenue_2026dynamic.csv"
      ],
      "metadata": {
        "id": "wFZp8CYwjcCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Requires: pandas, numpy, scikit-learn\n",
        "# pip install pandas numpy scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import os\n",
        "\n",
        "# -----------------------\n",
        "# Config / filenames\n",
        "# -----------------------\n",
        "OCC_FILE = \"parkingdata_streamlined.csv\"\n",
        "MONTHLY_REV_FILE = \"monthlyParkingRevenue.csv\"\n",
        "BASE_PRICE_FILE = \"basePrice.csv\"\n",
        "OUTPUT_PRED_CSV = \"predictedMonthlyRevenue_historical.csv\"\n",
        "\n",
        "# New prediction config\n",
        "FUTURE_OCC_FILE = \"2026predictedparkingdata_streamlined.csv\"\n",
        "FUTURE_OUTPUT_PRED_CSV = \"predictedMonthlyRevenue_2026standard.csv\"\n",
        "\n",
        "# For dynamic pricing scenario\n",
        "DYNAMIC_PRICE_FILE = \"dynamicModelSheet.csv\"\n",
        "DYNAMIC_OUTPUT_PRED_CSV = \"predictedMonthlyRevenue_2026dynamic.csv\"\n",
        "\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "LOTS = [\n",
        "    (\"lot2\", \"LOT 2 General\", \"LOT 2 Premium\"),\n",
        "    (\"lot3\", \"LOT 3\", None),\n",
        "    (\"lot4\", \"LOT 4 General\", \"LOT 4 Premium\"),\n",
        "    (\"lot5\", \"LOT 5\", None),\n",
        "    (\"lot6\", \"LOT 6\", None),\n",
        "]\n",
        "\n",
        "# -----------------------\n",
        "# Utility functions\n",
        "# -----------------------\n",
        "def load_data(occ_file=OCC_FILE, monthly_file=MONTHLY_REV_FILE, price_file=BASE_PRICE_FILE):\n",
        "    occ = pd.read_csv(occ_file)\n",
        "    monthly = pd.read_csv(monthly_file)\n",
        "    price = pd.read_csv(price_file)\n",
        "    return occ, monthly, price\n",
        "\n",
        "def preprocess_occupancy_df(occ):\n",
        "    occ = occ.copy()\n",
        "    occ['Date'] = pd.to_datetime(occ['Date'])\n",
        "    occ['year'] = occ['Date'].dt.year\n",
        "    occ['month'] = occ['Date'].dt.month\n",
        "    occ = occ[occ['year'] != 2024]\n",
        "    occ_cols = [c for c in occ.columns if ('Occupied' in c) or ('% Capacity' in c)]\n",
        "    occ[occ_cols] = occ[occ_cols].replace({0: np.nan, -1: np.nan})\n",
        "    return occ\n",
        "\n",
        "def build_daily_price_matrix(occ, price_df):\n",
        "    occ = occ.copy()\n",
        "    if 'UtilizationRate' not in price_df.columns:\n",
        "        raise ValueError(\"basePrice.csv must have a column called 'UtilizationRate'\")\n",
        "    util_rates = price_df['UtilizationRate'].astype(float).values\n",
        "    sort_idx = np.argsort(util_rates)\n",
        "    util_rates = util_rates[sort_idx]\n",
        "    price_df_cols = {c.lower(): c for c in price_df.columns}\n",
        "    for shortname, general_pref, premium_pref in LOTS:\n",
        "        # General\n",
        "        if general_pref:\n",
        "            util_col = f\"{general_pref} % Capacity\"\n",
        "            occ_col = f\"{general_pref} Occupied\" if f\"{general_pref} Occupied\" in occ.columns else None\n",
        "            spaces_col = f\"{general_pref} Spaces\" if f\"{general_pref} Spaces\" in occ.columns else None\n",
        "            ux = None\n",
        "            if util_col in occ.columns:\n",
        "                ux = occ[util_col].astype(float)\n",
        "            elif occ_col and spaces_col:\n",
        "                ux = occ[occ_col].astype(float) / occ[spaces_col].astype(float)\n",
        "            if ux is not None:\n",
        "                price_col_name = None\n",
        "                candidate = (shortname + \"General\").lower()\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if candidate in c_lower or shortname in c_lower:\n",
        "                        if 'general' in c_lower or ('premium' not in c_lower and 'general' not in c_lower):\n",
        "                            price_col_name = c_orig\n",
        "                exact_gen = f\"{shortname}general\"\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if exact_gen in c_lower:\n",
        "                        price_col_name = c_orig\n",
        "                        break\n",
        "                if price_col_name is None:\n",
        "                    numeric_cols = [c for c in price_df.columns if c != 'UtilizationRate']\n",
        "                    price_col_name = numeric_cols[0]\n",
        "                price_vals = price_df[price_col_name].astype(float).values[sort_idx]\n",
        "                daily_price_col = f\"{shortname}_general_price\"\n",
        "                occ[daily_price_col] = np.interp(ux.fillna(0).values, util_rates, price_vals)\n",
        "                if occ_col:\n",
        "                    occ[f\"{shortname}_general_est_revenue\"] = occ[daily_price_col] * occ[occ_col].astype(float)\n",
        "        # Premium\n",
        "        if premium_pref:\n",
        "            util_col = f\"{premium_pref} % Capacity\"\n",
        "            occ_col = f\"{premium_pref} Occupied\" if f\"{premium_pref} Occupied\" in occ.columns else None\n",
        "            spaces_col = f\"{premium_pref} Spaces\" if f\"{premium_pref} Spaces\" in occ.columns else None\n",
        "            ux = None\n",
        "            if util_col in occ.columns:\n",
        "                ux = occ[util_col].astype(float)\n",
        "            elif occ_col and spaces_col:\n",
        "                ux = occ[occ_col].astype(float) / occ[spaces_col].astype(float)\n",
        "            if ux is not None:\n",
        "                price_col_name = None\n",
        "                candidate = (shortname + \"Premium\").lower()\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if candidate in c_lower or shortname in c_lower:\n",
        "                        price_col_name = c_orig\n",
        "                exact_prem = f\"{shortname}premium\"\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if exact_prem in c_lower:\n",
        "                        price_col_name = c_orig\n",
        "                        break\n",
        "                if price_col_name is None:\n",
        "                    numeric_cols = [c for c in price_df.columns if c != 'UtilizationRate']\n",
        "                    price_col_name = numeric_cols[0]\n",
        "                price_vals = price_df[price_col_name].astype(float).values[sort_idx]\n",
        "                daily_price_col = f\"{shortname}_premium_price\"\n",
        "                occ[daily_price_col] = np.interp(ux.fillna(0).values, util_rates, price_vals)\n",
        "                if occ_col:\n",
        "                    occ[f\"{shortname}_premium_est_revenue\"] = occ[daily_price_col] * occ[occ_col].astype(float)\n",
        "    return occ\n",
        "\n",
        "def aggregate_monthly_features(occ_with_prices):\n",
        "    df = occ_with_prices.copy()\n",
        "    features = []\n",
        "    for (y, m), grp in df.groupby(['year','month']):\n",
        "        feat = {'year': int(y), 'month': int(m)}\n",
        "        for shortname, general_pref, premium_pref in LOTS:\n",
        "            util_cols = [c for c in grp.columns if (\"% Capacity\" in c) and (shortname.replace(\"lot\",\"LOT \").lower() in c.lower())]\n",
        "            if util_cols:\n",
        "                util = grp[util_cols[0]].dropna()\n",
        "                feat[f\"{shortname}_avg_util\"] = util.mean() if not util.empty else np.nan\n",
        "                feat[f\"{shortname}_std_util\"] = util.std() if not util.empty else np.nan\n",
        "            else:\n",
        "                feat[f\"{shortname}_avg_util\"] = np.nan\n",
        "                feat[f\"{shortname}_std_util\"] = np.nan\n",
        "            gen_price_col = f\"{shortname}_general_price\"\n",
        "            prem_price_col = f\"{shortname}_premium_price\"\n",
        "            feat[f\"{shortname}_avg_price_general\"] = grp[gen_price_col].mean() if gen_price_col in grp else np.nan\n",
        "            feat[f\"{shortname}_avg_price_premium\"] = grp[prem_price_col].mean() if prem_price_col in grp else np.nan\n",
        "            est_rev_cols = [c for c in grp.columns if (f\"{shortname}_\" in c) and (\"est_revenue\" in c)]\n",
        "            feat[f\"{shortname}_sum_est_revenue\"] = grp[est_rev_cols].sum(axis=0).sum() if est_rev_cols else np.nan\n",
        "        est_rev_cols_all = [c for c in grp.columns if \"est_revenue\" in c]\n",
        "        feat['total_estimated_revenue_all_lots'] = grp[est_rev_cols_all].sum(axis=0).sum() if est_rev_cols_all else np.nan\n",
        "        features.append(feat)\n",
        "    feat_df = pd.DataFrame(features).sort_values(['year','month']).reset_index(drop=True)\n",
        "    return feat_df\n",
        "\n",
        "def prepare_labels(monthly_df):\n",
        "    df = monthly_df.copy()\n",
        "    revenue_col = None\n",
        "    for c in df.columns:\n",
        "        if c.lower() in ('revenue','total_revenue','rev'):\n",
        "            revenue_col = c\n",
        "            break\n",
        "    if not revenue_col:\n",
        "        revenue_col = df.columns[-1]\n",
        "    df = df.rename(columns={revenue_col:'revenue'})\n",
        "    df['year'] = df['year'].astype(int)\n",
        "    if df['month'].dtype == object:\n",
        "        try:\n",
        "            df['month'] = pd.to_datetime(df['month'], format='%B').dt.month\n",
        "        except Exception:\n",
        "            df['month'] = pd.to_datetime(df['month']).dt.month\n",
        "    df['revenue'] = df['revenue'].astype(float)\n",
        "    return df[['year','month','revenue']]\n",
        "\n",
        "def create_train_test_split(feature_df, labels_df, test_size=TEST_SIZE, random_state=RANDOM_SEED):\n",
        "    merged = pd.merge(feature_df, labels_df, on=['year','month'], how='inner')\n",
        "    month_ids = merged[['year','month']].drop_duplicates().reset_index(drop=True)\n",
        "    train_idx, test_idx = train_test_split(month_ids.index.values, test_size=test_size, random_state=random_state)\n",
        "    train_months = month_ids.loc[train_idx]\n",
        "    test_months = month_ids.loc[test_idx]\n",
        "    train_df = merged.merge(train_months, on=['year','month'], how='inner')\n",
        "    test_df = merged.merge(test_months, on=['year','month'], how='inner')\n",
        "    return train_df, test_df, merged\n",
        "\n",
        "def train_and_evaluate(train_df, test_df, feature_columns=None, random_state=RANDOM_SEED):\n",
        "    exclude = {'year','month','revenue'}\n",
        "    if feature_columns is None:\n",
        "        feature_columns = [c for c in train_df.columns if np.issubdtype(train_df[c].dtype, np.number) and c not in exclude]\n",
        "    X_train, y_train = train_df[feature_columns].fillna(0), train_df['revenue']\n",
        "    X_test, y_test = test_df[feature_columns].fillna(0), test_df['revenue']\n",
        "    model = RandomForestRegressor(n_estimators=200, random_state=random_state, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae, rmse = mean_absolute_error(y_test, y_pred), mean_squared_error(y_test, y_pred)**0.5\n",
        "    print(f\"Test MAE: {mae:,.2f}\")\n",
        "    print(f\"Test RMSE: {rmse:,.2f}\")\n",
        "    return model, feature_columns, mae, rmse\n",
        "\n",
        "def predict_all_months(feature_df, model, feature_columns):\n",
        "    df = feature_df.copy()\n",
        "    preds = model.predict(df[feature_columns].fillna(0))\n",
        "    df['predictedRevenue'] = np.round(preds, 2)\n",
        "    return df[['year','month','predictedRevenue']]\n",
        "\n",
        "# -----------------------\n",
        "# Future prediction function\n",
        "# -----------------------\n",
        "def predict_future_revenue(model, feature_columns, occ_path, price_path, output_path):\n",
        "    print(\"\\n=== Predicting Future (2026) Monthly Revenue ===\")\n",
        "    occ_future = pd.read_csv(occ_path)\n",
        "    price = pd.read_csv(price_path)\n",
        "    occ_future = preprocess_occupancy_df(occ_future)\n",
        "    occ_with_prices = build_daily_price_matrix(occ_future, price)\n",
        "    monthly_features = aggregate_monthly_features(occ_with_prices)\n",
        "    print(f\"2026 monthly feature shape: {monthly_features.shape}\")\n",
        "    preds_df = predict_all_months(monthly_features, model, feature_columns)\n",
        "    preds_df.to_csv(output_path, index=False)\n",
        "    print(f\"Future predictions saved to {output_path}\")\n",
        "    print(preds_df.head(10))\n",
        "    return preds_df\n",
        "\n",
        "# -----------------------\n",
        "# Main pipeline\n",
        "# -----------------------\n",
        "def main_pipeline():\n",
        "    print(\"Loading data...\")\n",
        "    occ, monthly, price = load_data()\n",
        "    print(\"Preprocessing occupancy data...\")\n",
        "    occ_clean = preprocess_occupancy_df(occ)\n",
        "    print(\"Computing daily prices from base price table...\")\n",
        "    occ_with_prices = build_daily_price_matrix(occ_clean, price)\n",
        "    print(\"Aggregating monthly features...\")\n",
        "    feature_df = aggregate_monthly_features(occ_with_prices)\n",
        "    print(f\"Monthly features shape: {feature_df.shape}\")\n",
        "    labels = prepare_labels(monthly)\n",
        "    print(f\"Monthly labels shape: {labels.shape}\")\n",
        "    train_df, test_df, _ = create_train_test_split(feature_df, labels)\n",
        "    print(f\"Training months: {len(train_df[['year','month']].drop_duplicates())}, Testing months: {len(test_df[['year','month']].drop_duplicates())}\")\n",
        "    print(\"Training Random Forest...\")\n",
        "    model, feature_cols, mae, rmse = train_and_evaluate(train_df, test_df)\n",
        "    print(\"Predicting revenue for historical occupancy...\")\n",
        "    preds_df = predict_all_months(feature_df, model, feature_cols)\n",
        "    preds_df.to_csv(OUTPUT_PRED_CSV, index=False)\n",
        "    print(f\"Historical predictions saved to {OUTPUT_PRED_CSV}\")\n",
        "\n",
        "    # === Standard 2026 prediction (using basePrice.csv) ===\n",
        "    if os.path.exists(FUTURE_OCC_FILE):\n",
        "        predict_future_revenue(\n",
        "            model,\n",
        "            feature_cols,\n",
        "            FUTURE_OCC_FILE,\n",
        "            BASE_PRICE_FILE,\n",
        "            FUTURE_OUTPUT_PRED_CSV\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Future occupancy file not found: {FUTURE_OCC_FILE}. Skipping standard future prediction.\")\n",
        "\n",
        "    # === Dynamic pricing 2026 prediction (using dynamicModelSheet.csv) ===\n",
        "    if os.path.exists(FUTURE_OCC_FILE) and os.path.exists(DYNAMIC_PRICE_FILE):\n",
        "        print(\"\\n\\n=== Running DYNAMIC PRICING Scenario ===\")\n",
        "        predict_future_revenue(\n",
        "            model,\n",
        "            feature_cols,\n",
        "            FUTURE_OCC_FILE,\n",
        "            DYNAMIC_PRICE_FILE,\n",
        "            DYNAMIC_OUTPUT_PRED_CSV\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Missing files for dynamic prediction: {FUTURE_OCC_FILE} or {DYNAMIC_PRICE_FILE}. Skipping dynamic prediction.\")\n",
        "\n",
        "    return model, feature_cols\n",
        "\n",
        "main_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXw96EXIWI2a",
        "outputId": "e3c746fd-14e6-4ac2-c462-7861f3d9ac12"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Preprocessing occupancy data...\n",
            "Computing daily prices from base price table...\n",
            "Aggregating monthly features...\n",
            "Monthly features shape: (40, 28)\n",
            "Monthly labels shape: (97, 3)\n",
            "Training months: 30, Testing months: 8\n",
            "Training Random Forest...\n",
            "Test MAE: 132,808.83\n",
            "Test RMSE: 191,726.01\n",
            "Predicting revenue for historical occupancy...\n",
            "Historical predictions saved to predictedMonthlyRevenue_historical.csv\n",
            "\n",
            "=== Predicting Future (2026) Monthly Revenue ===\n",
            "2026 monthly feature shape: (12, 28)\n",
            "Future predictions saved to predictedMonthlyRevenue_2026standard.csv\n",
            "   year  month  predictedRevenue\n",
            "0  2026      1        2376899.73\n",
            "1  2026      2        2445304.99\n",
            "2  2026      3        2851495.72\n",
            "3  2026      4        2760934.77\n",
            "4  2026      5        3705879.85\n",
            "5  2026      6        3644410.50\n",
            "6  2026      7        3882851.05\n",
            "7  2026      8        3832409.37\n",
            "8  2026      9        2751250.38\n",
            "9  2026     10        3000107.96\n",
            "\n",
            "\n",
            "=== Running DYNAMIC PRICING Scenario ===\n",
            "\n",
            "=== Predicting Future (2026) Monthly Revenue ===\n",
            "2026 monthly feature shape: (12, 28)\n",
            "Future predictions saved to predictedMonthlyRevenue_2026dynamic.csv\n",
            "   year  month  predictedRevenue\n",
            "0  2026      1        2437838.03\n",
            "1  2026      2        2607978.22\n",
            "2  2026      3        3028643.83\n",
            "3  2026      4        2968179.74\n",
            "4  2026      5        3706395.71\n",
            "5  2026      6        3770416.00\n",
            "6  2026      7        3886110.58\n",
            "7  2026      8        3896643.17\n",
            "8  2026      9        2933206.59\n",
            "9  2026     10        3113266.02\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42),\n",
              " ['lot2_avg_util',\n",
              "  'lot2_std_util',\n",
              "  'lot2_avg_price_general',\n",
              "  'lot2_avg_price_premium',\n",
              "  'lot2_sum_est_revenue',\n",
              "  'lot3_avg_util',\n",
              "  'lot3_std_util',\n",
              "  'lot3_avg_price_general',\n",
              "  'lot3_avg_price_premium',\n",
              "  'lot3_sum_est_revenue',\n",
              "  'lot4_avg_util',\n",
              "  'lot4_std_util',\n",
              "  'lot4_avg_price_general',\n",
              "  'lot4_avg_price_premium',\n",
              "  'lot4_sum_est_revenue',\n",
              "  'lot5_avg_util',\n",
              "  'lot5_std_util',\n",
              "  'lot5_avg_price_general',\n",
              "  'lot5_avg_price_premium',\n",
              "  'lot5_sum_est_revenue',\n",
              "  'lot6_avg_util',\n",
              "  'lot6_std_util',\n",
              "  'lot6_avg_price_general',\n",
              "  'lot6_avg_price_premium',\n",
              "  'lot6_sum_est_revenue',\n",
              "  'total_estimated_revenue_all_lots'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Old code (Ignore)**\n"
      ],
      "metadata": {
        "id": "wSk-AEO8iycf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sQiiD38b8zf",
        "outputId": "74842c52-8c33-48c9-ec9f-51bac011c366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Preprocessing occupancy data...\n",
            "Computing daily prices from base price table...\n",
            "Aggregating monthly features...\n",
            "Monthly features shape: (40, 34)\n",
            "Monthly labels shape: (97, 3)\n",
            "Training months: 30, Testing months: 8\n",
            "Training Random Forest...\n",
            "Test MAE: 159,449.91\n",
            "Test RMSE: 233,996.54\n",
            "Predicting revenue for all months present in occupancy data...\n",
            "Predictions saved to PredictionMonthlyRevenue.csv (rows: 40)\n",
            "Sample predictions:\n",
            "   year  month  predictedRevenue\n",
            "0  2020      5         501767.01\n",
            "1  2020      6         782153.27\n",
            "2  2020      7         951528.04\n",
            "3  2020      8        1017037.91\n",
            "4  2020      9        1041777.10\n",
            "5  2020     10        1240382.81\n",
            "6  2020     11        1173063.87\n",
            "7  2020     12         940699.00\n",
            "8  2021      1         870833.22\n",
            "9  2021      2         907679.31\n"
          ]
        }
      ],
      "source": [
        "# Requires: pandas, numpy, scikit-learn\n",
        "# pip install pandas numpy scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import os\n",
        "\n",
        "# -----------------------\n",
        "# Config / filenames\n",
        "# -----------------------\n",
        "OCC_FILE = \"parkingdata_streamlined.csv\"\n",
        "MONTHLY_REV_FILE = \"monthlyParkingRevenue.csv\"\n",
        "BASE_PRICE_FILE = \"basePrice.csv\"\n",
        "OUTPUT_PRED_CSV = \"PredictionMonthlyRevenue.csv\"\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.2  # fraction of months to use as test set\n",
        "\n",
        "# List of lots and the column naming patterns expected in the daily dataset:\n",
        "LOTS = [\n",
        "    (\"lot2\", \"LOT 2 General\", \"LOT 2 Premium\"),\n",
        "    (\"lot3\", \"LOT 3\", None),\n",
        "    (\"lot4\", \"LOT 4 General\", \"LOT 4 Premium\"),\n",
        "    (\"lot5\", \"LOT 5\", None),\n",
        "    (\"lot6\", \"LOT 6\", None),\n",
        "]\n",
        "# Mapping LOT tuple: (shortname, general_col_prefix, premium_col_prefix or None)\n",
        "\n",
        "# -----------------------\n",
        "# Utility functions\n",
        "# -----------------------\n",
        "def load_data(occ_file=OCC_FILE, monthly_file=MONTHLY_REV_FILE, price_file=BASE_PRICE_FILE):\n",
        "    occ = pd.read_csv(occ_file)\n",
        "    monthly = pd.read_csv(monthly_file)\n",
        "    price = pd.read_csv(price_file)\n",
        "    return occ, monthly, price\n",
        "\n",
        "def preprocess_occupancy_df(occ):\n",
        "    # parse date\n",
        "    occ = occ.copy()\n",
        "    occ['Date'] = pd.to_datetime(occ['Date'])\n",
        "    occ['year'] = occ['Date'].dt.year\n",
        "    occ['month'] = occ['Date'].dt.month\n",
        "    # drop entire year 2024 in occupancy if present (user requested to ignore)\n",
        "    occ = occ[occ['year'] != 2024]\n",
        "    # Replace missing / placeholder occupancy values with NaN\n",
        "    # We'll remove zeros and -1 in columns that represent occupancies or utilization percentages.\n",
        "    # Identify relevant columns automatically:\n",
        "    # any column with 'Occupied' or '% Capacity' in it\n",
        "    occ_cols = [c for c in occ.columns if ('Occupied' in c) or ('% Capacity' in c)]\n",
        "    # Replace 0 or -1 with NaN\n",
        "    occ[occ_cols] = occ[occ_cols].replace({0: np.nan, -1: np.nan})\n",
        "    return occ\n",
        "\n",
        "def build_daily_price_matrix(occ, price_df):\n",
        "    \"\"\"\n",
        "    For each occupancy row and for each lot, compute price by interpolation:\n",
        "    - For each lot we will compute a day's utilization (percent capacity column or use occupied/spaces).\n",
        "    - Then use np.interp based on price_df['UtilizationRate'] to get price.\n",
        "    Returns occ with new price columns e.g. 'lot2_price', and also daily estimated revenue per lot: 'lot2_est_revenue'\n",
        "    \"\"\"\n",
        "    occ = occ.copy()\n",
        "    # Normalize price_df UtilizationRate to fraction (it may be 0,0.01,... as given)\n",
        "    if 'UtilizationRate' not in price_df.columns:\n",
        "        raise ValueError(\"basePrice.csv must have a column called 'UtilizationRate'\")\n",
        "    util_rates = price_df['UtilizationRate'].astype(float).values\n",
        "    # For numeric stability ensure it's sorted\n",
        "    sort_idx = np.argsort(util_rates)\n",
        "    util_rates = util_rates[sort_idx]\n",
        "    # For each lot shortname, find column names in price df (case-insensitive)\n",
        "    price_df_cols = {c.lower(): c for c in price_df.columns}\n",
        "    # For each LOT in LOTS, compute utilization and then price\n",
        "    for shortname, general_pref, premium_pref in LOTS:\n",
        "        # General lot\n",
        "        if general_pref:\n",
        "            util_col = f\"{general_pref} % Capacity\"\n",
        "            occ_col = f\"{general_pref} Occupied\" if f\"{general_pref} Occupied\" in occ.columns else None\n",
        "            spaces_col = f\"{general_pref} Spaces\" if f\"{general_pref} Spaces\" in occ.columns else None\n",
        "            ux = None\n",
        "            if util_col in occ.columns:\n",
        "                ux = occ[util_col].astype(float)  # likely already 0-1\n",
        "            elif occ_col in occ.columns and spaces_col in occ.columns:\n",
        "                ux = occ[occ_col].astype(float) / occ[spaces_col].astype(float)\n",
        "            if ux is not None:\n",
        "                # find matching price column in price_df for this general lot (case-insensitive)\n",
        "                price_col_name = None\n",
        "                candidate = (shortname + \"General\").lower()  # e.g., lot2general\n",
        "                # try to find any column in price_df whose lower contains lot shortname\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if candidate in c_lower or shortname in c_lower:\n",
        "                        # prefer ones containing 'general' if possible\n",
        "                        if 'general' in c_lower or ('premium' not in c_lower and 'general' not in c_lower):\n",
        "                            price_col_name = c_orig\n",
        "                            # but keep looking to prefer exact general match\n",
        "                # fallback heuristics: look for 'general' + shortname\n",
        "                exact_gen = f\"{shortname}general\"\n",
        "                found = None\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if exact_gen in c_lower:\n",
        "                        found = c_orig\n",
        "                        break\n",
        "                if found:\n",
        "                    price_col_name = found\n",
        "                # if not found, try to match by the most similar name:\n",
        "                if price_col_name is None:\n",
        "                    # last resort: choose the first numeric column except UtilizationRate\n",
        "                    numeric_cols = [c for c in price_df.columns if c != 'UtilizationRate']\n",
        "                    price_col_name = numeric_cols[0] if numeric_cols else None\n",
        "                # Now interpolate\n",
        "                price_vals = price_df[price_col_name].astype(float).values[sort_idx]\n",
        "                # compute price for each row by interpolation on util_rates\n",
        "                daily_price_col = f\"{shortname}_general_price\"\n",
        "                occ[daily_price_col] = np.interp(ux.fillna(0).values, util_rates, price_vals)\n",
        "                # estimated revenue = price * occupied\n",
        "                if occ_col in occ.columns:\n",
        "                    occ[f\"{shortname}_general_est_revenue\"] = occ[daily_price_col] * occ[occ_col].astype(float)\n",
        "                else:\n",
        "                    occ[f\"{shortname}_general_est_revenue\"] = np.nan\n",
        "        # Premium lot\n",
        "        if premium_pref:\n",
        "            util_col = f\"{premium_pref} % Capacity\"\n",
        "            occ_col = f\"{premium_pref} Occupied\" if f\"{premium_pref} Occupied\" in occ.columns else None\n",
        "            spaces_col = f\"{premium_pref} Spaces\" if f\"{premium_pref} Spaces\" in occ.columns else None\n",
        "            ux = None\n",
        "            if util_col in occ.columns:\n",
        "                ux = occ[util_col].astype(float)\n",
        "            elif occ_col in occ.columns and spaces_col in occ.columns:\n",
        "                ux = occ[occ_col].astype(float) / occ[spaces_col].astype(float)\n",
        "            if ux is not None:\n",
        "                # find price column for premium\n",
        "                price_col_name = None\n",
        "                candidate = (shortname + \"Premium\").lower()\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if candidate in c_lower or shortname in c_lower:\n",
        "                        price_col_name = c_orig\n",
        "                exact_prem = f\"{shortname}premium\"\n",
        "                found = None\n",
        "                for c_lower, c_orig in price_df_cols.items():\n",
        "                    if exact_prem in c_lower:\n",
        "                        found = c_orig\n",
        "                        break\n",
        "                if found:\n",
        "                    price_col_name = found\n",
        "                if price_col_name is None:\n",
        "                    numeric_cols = [c for c in price_df.columns if c != 'UtilizationRate']\n",
        "                    price_col_name = numeric_cols[0] if numeric_cols else None\n",
        "                price_vals = price_df[price_col_name].astype(float).values[sort_idx]\n",
        "                daily_price_col = f\"{shortname}_premium_price\"\n",
        "                occ[daily_price_col] = np.interp(ux.fillna(0).values, util_rates, price_vals)\n",
        "                if occ_col in occ.columns:\n",
        "                    occ[f\"{shortname}_premium_est_revenue\"] = occ[daily_price_col] * occ[occ_col].astype(float)\n",
        "                else:\n",
        "                    occ[f\"{shortname}_premium_est_revenue\"] = np.nan\n",
        "    return occ\n",
        "\n",
        "def aggregate_monthly_features(occ_with_prices):\n",
        "    \"\"\"\n",
        "    For each year-month produce a set of features:\n",
        "    For each lot shortname:\n",
        "      - avg_utilization\n",
        "      - std_utilization\n",
        "      - avg_price (general/premium)\n",
        "      - total_occupied_days (sum of occupied over days)\n",
        "      - sum_estimated_revenue\n",
        "      - occupancy_days_count (number of valid days)\n",
        "    Also aggregate across all lots:\n",
        "      - total_estimated_revenue_all_lots\n",
        "      - mean_utilization_all_lots\n",
        "    Returns a DataFrame indexed by (year,month) with features.\n",
        "    \"\"\"\n",
        "    df = occ_with_prices.copy()\n",
        "    groups = []\n",
        "    features = []\n",
        "    g = df.groupby(['year','month'])\n",
        "    for (y,m), grp in g:\n",
        "        feat = {'year': int(y), 'month': int(m)}\n",
        "        # For each lot:\n",
        "        for shortname, general_pref, premium_pref in LOTS:\n",
        "            # UTIL columns likely named like 'LOT X General % Capacity' etc. We'll search\n",
        "            # find any columns in grp for utilization (contain shortname and '% Capacity' or use est_revenue columns)\n",
        "            # average utilization per lot: attempt to look for any \"% Capacity\" column containing the lot's canonical name\n",
        "            util_candidate_cols = [c for c in grp.columns if (\"% Capacity\" in c) and (shortname.replace(\"lot\",\"LOT \").lower() in c.lower() or shortname in c.lower() or shortname.replace(\"lot\",\"\").lower() in c.lower())]\n",
        "            # fallback: look for 'Occupied' and 'Spaces' to compute utilization\n",
        "            avg_util = np.nan\n",
        "            if util_candidate_cols:\n",
        "                # take first candidate\n",
        "                avg_util = grp[util_candidate_cols[0]].dropna().mean()\n",
        "                feat[f\"{shortname}_avg_util\"] = float(avg_util) if not np.isnan(avg_util) else np.nan\n",
        "                feat[f\"{shortname}_std_util\"] = float(grp[util_candidate_cols[0]].dropna().std()) if not grp[util_candidate_cols[0]].dropna().empty else np.nan\n",
        "            else:\n",
        "                # try occupancy/spaces\n",
        "                occ_cols = [c for c in grp.columns if ('Occupied' in c) and (shortname in c.lower() or shortname.replace(\"lot\",\"\").lower() in c.lower())]\n",
        "                spaces_cols = [c for c in grp.columns if ('Spaces' in c) and (shortname in c.lower() or shortname.replace(\"lot\",\"\").lower() in c.lower())]\n",
        "                if occ_cols and spaces_cols:\n",
        "                    util_series = grp[occ_cols[0]].astype(float) / grp[spaces_cols[0]].astype(float)\n",
        "                    feat[f\"{shortname}_avg_util\"] = float(util_series.dropna().mean()) if not util_series.dropna().empty else np.nan\n",
        "                    feat[f\"{shortname}_std_util\"] = float(util_series.dropna().std()) if not util_series.dropna().empty else np.nan\n",
        "                else:\n",
        "                    feat[f\"{shortname}_avg_util\"] = np.nan\n",
        "                    feat[f\"{shortname}_std_util\"] = np.nan\n",
        "            # average price columns produced earlier:\n",
        "            gen_price_col = f\"{shortname}_general_price\"\n",
        "            prem_price_col = f\"{shortname}_premium_price\"\n",
        "            if gen_price_col in grp.columns:\n",
        "                feat[f\"{shortname}_avg_price_general\"] = float(grp[gen_price_col].dropna().mean()) if not grp[gen_price_col].dropna().empty else np.nan\n",
        "            else:\n",
        "                feat[f\"{shortname}_avg_price_general\"] = np.nan\n",
        "            if prem_price_col in grp.columns:\n",
        "                feat[f\"{shortname}_avg_price_premium\"] = float(grp[prem_price_col].dropna().mean()) if not grp[prem_price_col].dropna().empty else np.nan\n",
        "            else:\n",
        "                feat[f\"{shortname}_avg_price_premium\"] = np.nan\n",
        "            # sum estimated revenue:\n",
        "            est_rev_cols = [c for c in grp.columns if (f\"{shortname}_\" in c) and (\"est_revenue\" in c)]\n",
        "            if est_rev_cols:\n",
        "                feat[f\"{shortname}_sum_est_revenue\"] = float(grp[est_rev_cols].sum(axis=0).sum())  # sum across rows and columns (if general+premium)\n",
        "            else:\n",
        "                feat[f\"{shortname}_sum_est_revenue\"] = np.nan\n",
        "            # total occupied (sum)\n",
        "            occ_cols_for_short = [c for c in grp.columns if ('Occupied' in c) and (shortname.replace(\"lot\",\"\").replace(\" \", \"\") in c.lower().replace(\" \", \"\"))]\n",
        "            if occ_cols_for_short:\n",
        "                # If there are multiple occupied columns (general/premium) sum them\n",
        "                try:\n",
        "                    occ_total = grp[occ_cols_for_short].astype(float).sum(axis=1).sum()\n",
        "                    feat[f\"{shortname}_sum_occupied\"] = float(occ_total)\n",
        "                except Exception:\n",
        "                    feat[f\"{shortname}_sum_occupied\"] = np.nan\n",
        "            else:\n",
        "                feat[f\"{shortname}_sum_occupied\"] = np.nan\n",
        "        # global aggregates\n",
        "        est_rev_cols_all = [c for c in grp.columns if \"est_revenue\" in c]\n",
        "        feat['total_estimated_revenue_all_lots'] = float(grp[est_rev_cols_all].sum(axis=1).sum()) if est_rev_cols_all else np.nan\n",
        "        # mean utilization across lots (average of avg_util columns)\n",
        "        avg_utils = [feat.get(f\"{shortname}_avg_util\") for shortname,_,_ in LOTS if not np.isnan(feat.get(f\"{shortname}_avg_util\", np.nan))]\n",
        "        feat['mean_util_all_lots'] = float(np.nanmean(avg_utils)) if avg_utils and not np.isnan(np.nanmean(avg_utils)) else np.nan\n",
        "        features.append(feat)\n",
        "    feat_df = pd.DataFrame(features)\n",
        "    # sort\n",
        "    feat_df = feat_df.sort_values(['year','month']).reset_index(drop=True)\n",
        "    return feat_df\n",
        "\n",
        "def prepare_labels(monthly_df):\n",
        "    \"\"\"\n",
        "    monthly_df: expected columns 'year', 'month', 'revenue' (or 'revenue' might be last column)\n",
        "    Return DataFrame with year, month, revenue\n",
        "    \"\"\"\n",
        "    df = monthly_df.copy()\n",
        "    # ensure the revenue column exists; try common names\n",
        "    revenue_col = None\n",
        "    for c in df.columns:\n",
        "        if c.lower() in ('revenue','total_revenue','rev','revenue_total'):\n",
        "            revenue_col = c\n",
        "            break\n",
        "    if revenue_col is None:\n",
        "        # try last column as fallback\n",
        "        revenue_col = df.columns[-1]\n",
        "    df = df.rename(columns={revenue_col: 'revenue'})\n",
        "    # Ensure year and month exist and are integers\n",
        "    df['year'] = df['year'].astype(int)\n",
        "    # month may be string -> convert to numeric month if needed\n",
        "    if df['month'].dtype == object:\n",
        "        # try parsing month names\n",
        "        try:\n",
        "            df['month'] = pd.to_datetime(df['month'], format='%B').dt.month\n",
        "        except Exception:\n",
        "            # try format like 'Jul-17' or 'Jul-2017' -> fallback: try pd.to_datetime\n",
        "            try:\n",
        "                df['month'] = pd.to_datetime(df['month']).dt.month\n",
        "            except Exception:\n",
        "                # if still failing, try extracting integer\n",
        "                df['month'] = df['month'].astype(int)\n",
        "    df['month'] = df['month'].astype(int)\n",
        "    df['revenue'] = df['revenue'].astype(float)\n",
        "    return df[['year','month','revenue']]\n",
        "\n",
        "def create_train_test_split(feature_df, labels_df, test_size=TEST_SIZE, random_state=RANDOM_SEED):\n",
        "    # Join features and labels to get rows for training/testing (only months that exist in both)\n",
        "    merged = pd.merge(feature_df, labels_df, on=['year','month'], how='inner')\n",
        "    # We'll randomly split month groups\n",
        "    # Get unique (year,month) tuples present in merged\n",
        "    month_ids = merged[['year','month']].drop_duplicates().reset_index(drop=True)\n",
        "    # randomize and split\n",
        "    train_idx, test_idx = train_test_split(month_ids.index.values, test_size=test_size, random_state=random_state)\n",
        "    train_months = month_ids.loc[train_idx]\n",
        "    test_months = month_ids.loc[test_idx]\n",
        "    # get the rows\n",
        "    train_df = merged.merge(train_months, on=['year','month'], how='inner')\n",
        "    test_df = merged.merge(test_months, on=['year','month'], how='inner')\n",
        "    return train_df, test_df, merged\n",
        "\n",
        "def train_and_evaluate(train_df, test_df, feature_columns=None, random_state=RANDOM_SEED):\n",
        "    # prepare X, y\n",
        "    if feature_columns is None:\n",
        "        # take all numeric columns except year, month, revenue\n",
        "        exclude = {'year','month','revenue'}\n",
        "        feature_columns = [c for c in train_df.columns if np.issubdtype(train_df[c].dtype, np.number) and c not in exclude]\n",
        "    X_train = train_df[feature_columns].fillna(0)\n",
        "    y_train = train_df['revenue'].values\n",
        "    X_test = test_df[feature_columns].fillna(0)\n",
        "    y_test = test_df['revenue'].values\n",
        "    rf_model = RandomForestRegressor(n_estimators=200, random_state=random_state, n_jobs=-1)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "    print(f\"Test MAE: {mae:,.2f}\")\n",
        "    print(f\"Test RMSE: {rmse:,.2f}\")\n",
        "    return rf_model, feature_columns, mae, rmse\n",
        "\n",
        "def predict_all_months(feature_df, model, feature_columns):\n",
        "    # Predict for every row in feature_df (which has year,month)\n",
        "    df = feature_df.copy()\n",
        "    X = df[feature_columns].fillna(0)\n",
        "    preds = model.predict(X)\n",
        "    df['predictedRevenue'] = preds\n",
        "    # Order properly by year then month\n",
        "    df = df.sort_values(['year','month']).reset_index(drop=True)\n",
        "    out = df[['year','month','predictedRevenue']].copy()\n",
        "    # round predictedRevenue to 2 decimals\n",
        "    out['predictedRevenue'] = out['predictedRevenue'].round(2)\n",
        "    return out\n",
        "\n",
        "# -----------------------\n",
        "# Main pipeline\n",
        "# -----------------------\n",
        "def main_pipeline(occ_file=OCC_FILE, monthly_file=MONTHLY_REV_FILE, price_file=BASE_PRICE_FILE, output_csv=OUTPUT_PRED_CSV):\n",
        "    print(\"Loading data...\")\n",
        "    occ, monthly, price = load_data(occ_file, monthly_file, price_file)\n",
        "    print(\"Preprocessing occupancy data...\")\n",
        "    occ_clean = preprocess_occupancy_df(occ)\n",
        "    print(\"Computing daily prices from base price table...\")\n",
        "    occ_with_prices = build_daily_price_matrix(occ_clean, price)\n",
        "    print(\"Aggregating monthly features...\")\n",
        "    feature_df = aggregate_monthly_features(occ_with_prices)\n",
        "    print(f\"Monthly features shape: {feature_df.shape}\")\n",
        "    labels = prepare_labels(monthly)\n",
        "    print(f\"Monthly labels shape: {labels.shape}\")\n",
        "    # Create train/test split (only months for which we have labels)\n",
        "    train_df, test_df, merged_df = create_train_test_split(feature_df, labels)\n",
        "    print(f\"Training months: {train_df[['year','month']].drop_duplicates().shape[0]}, Testing months: {test_df[['year','month']].drop_duplicates().shape[0]}\")\n",
        "    # Train\n",
        "    print(\"Training Random Forest...\")\n",
        "    rf_model, feature_cols, mae, rmse = train_and_evaluate(train_df, test_df)\n",
        "    # Predict for all months with features (these are months derived from daily occupancy file)\n",
        "    print(\"Predicting revenue for all months present in occupancy data...\")\n",
        "    preds_df = predict_all_months(feature_df, rf_model, feature_cols)\n",
        "    # Save predictions CSV\n",
        "    #preds_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Predictions saved to {output_csv} (rows: {len(preds_df)})\")\n",
        "    # Also print a sample\n",
        "    print(\"Sample predictions:\")\n",
        "    print(preds_df.head(10))\n",
        "    return {\n",
        "        'model': rf_model,\n",
        "        'feature_columns': feature_cols,\n",
        "        'predictions_df': preds_df,\n",
        "        'train_df': train_df,\n",
        "        'test_df': test_df,\n",
        "        'feature_df': feature_df\n",
        "    }\n",
        "\n",
        "# Run the pipeline if files are present\n",
        "if __name__ == \"__main__\":\n",
        "    # Check files\n",
        "    missing = [f for f in [OCC_FILE, MONTHLY_REV_FILE, BASE_PRICE_FILE] if not os.path.exists(f)]\n",
        "    if missing:\n",
        "        print(\"The following required files are missing in the current directory:\", missing)\n",
        "        print(\"Place 'parkingdata_streamlined.csv', 'monthlyParkingRevenue.csv', and 'basePrice.csv' here and re-run.\")\n",
        "    else:\n",
        "        results = main_pipeline()\n"
      ]
    }
  ]
}